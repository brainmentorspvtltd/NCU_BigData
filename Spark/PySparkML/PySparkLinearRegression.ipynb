{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5331380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355d40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a644403",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('app_1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78948a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('headbrain.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3959ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age Range: string (nullable = true)\n",
      " |-- Head Size(cm^3): string (nullable = true)\n",
      " |-- Brain Weight(grams): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd2d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+-------------------+\n",
      "|Gender|Age Range|Head Size(cm^3)|Brain Weight(grams)|\n",
      "+------+---------+---------------+-------------------+\n",
      "|     1|        1|           4512|               1530|\n",
      "|     1|        1|           3738|               1297|\n",
      "|     1|        1|           4261|               1335|\n",
      "|     1|        1|           3777|               1282|\n",
      "|     1|        1|           4177|               1590|\n",
      "+------+---------+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9335418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae02466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tp.StructType([\n",
    "    tp.StructField(name='Gender', dataType=tp.IntegerType()),\n",
    "    tp.StructField(name='Age Range', dataType=tp.IntegerType()),\n",
    "    tp.StructField(name='Head Size(cm^3)', dataType=tp.IntegerType()),\n",
    "    tp.StructField(name='Brain Weight(grams)', dataType=tp.IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84792d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = spark.read.csv('headbrain.csv', schema=schema, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccd6f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: integer (nullable = true)\n",
      " |-- Age Range: integer (nullable = true)\n",
      " |-- Head Size(cm^3): integer (nullable = true)\n",
      " |-- Brain Weight(grams): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1e4cd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+-------------------+\n",
      "|Gender|Age Range|Head Size(cm^3)|Brain Weight(grams)|\n",
      "+------+---------+---------------+-------------------+\n",
      "|     1|        1|           4512|               1530|\n",
      "|     1|        1|           3738|               1297|\n",
      "|     1|        1|           4261|               1335|\n",
      "|     1|        1|           3777|               1282|\n",
      "|     1|        1|           4177|               1590|\n",
      "+------+---------+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9432ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show(5)\n",
    "new_df = df.drop(*['Gender', 'Age Range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c589fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|Head Size(cm^3)|Brain Weight(grams)|\n",
      "+---------------+-------------------+\n",
      "|           4512|               1530|\n",
      "|           3738|               1297|\n",
      "|           4261|               1335|\n",
      "|           3777|               1282|\n",
      "|           4177|               1590|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f273b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = my_df.drop(*['Gender', 'Age Range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da63c6",
   "metadata": {},
   "source": [
    "## Checking shape of data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38c11412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.count(), len(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9bd7038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|Head Size(cm^3)|Brain Weight(grams)|\n",
      "+---------------+-------------------+\n",
      "|           4512|               1530|\n",
      "|           3738|               1297|\n",
      "|           4261|               1335|\n",
      "|           3777|               1282|\n",
      "|           4177|               1590|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0cb43e",
   "metadata": {},
   "source": [
    "## Select Individual column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54c25d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|Head Size(cm^3)|\n",
      "+---------------+\n",
      "|           4512|\n",
      "|           3738|\n",
      "|           4261|\n",
      "|           3777|\n",
      "|           4177|\n",
      "+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.select('Head Size(cm^3)').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911758ec",
   "metadata": {},
   "source": [
    "## Describe DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f29cb22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+\n",
      "|summary|   Head Size(cm^3)|Brain Weight(grams)|\n",
      "+-------+------------------+-------------------+\n",
      "|  count|               237|                237|\n",
      "|   mean|3633.9915611814345|  1282.873417721519|\n",
      "| stddev| 365.2614224198132| 120.34044578645734|\n",
      "|    min|              2720|                955|\n",
      "|    max|              4747|               1635|\n",
      "+-------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.select('Head Size(cm^3)', 'Brain Weight(grams)').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeb8f0a",
   "metadata": {},
   "source": [
    "## Checking Null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cee7b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a7184b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = my_df.agg(*[fun.count(fun.when(fun.isnull(col), col)).alias(col) for col in new_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e5608f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|Head Size(cm^3)|Brain Weight(grams)|\n",
      "+---------------+-------------------+\n",
      "|              0|                  0|\n",
      "+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7995e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Gender|count|\n",
      "+------+-----+\n",
      "|     1|  134|\n",
      "|     2|  103|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.groupBy('Gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed354df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f81aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "StringIndexGender = StringIndexer(inputCol='Gender', outputCol='Gender_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d106da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = StringIndexGender.fit(my_df).transform(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "592ca2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+-------------------+--------+\n",
      "|Gender|Age Range|Head Size(cm^3)|Brain Weight(grams)|Gender_2|\n",
      "+------+---------+---------------+-------------------+--------+\n",
      "|     1|        1|           4512|               1530|     0.0|\n",
      "|     1|        1|           3738|               1297|     0.0|\n",
      "|     1|        1|           4261|               1335|     0.0|\n",
      "|     1|        1|           3777|               1282|     0.0|\n",
      "|     1|        1|           4177|               1590|     0.0|\n",
      "+------+---------+---------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fc9a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Gender_2|count|\n",
      "+--------+-----+\n",
      "|     0.0|  134|\n",
      "|     1.0|  103|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.groupBy('Gender_2').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ee62fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = OneHotEncoder(inputCols=['Gender_2'], outputCols=['Gender_3'])\n",
    "my_df = onehot.fit(my_df).transform(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc164d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+-------------------+--------+-------------+\n",
      "|Gender|Age Range|Head Size(cm^3)|Brain Weight(grams)|Gender_2|     Gender_3|\n",
      "+------+---------+---------------+-------------------+--------+-------------+\n",
      "|     1|        1|           4512|               1530|     0.0|(1,[0],[1.0])|\n",
      "|     1|        1|           3738|               1297|     0.0|(1,[0],[1.0])|\n",
      "|     1|        1|           4261|               1335|     0.0|(1,[0],[1.0])|\n",
      "|     1|        1|           3777|               1282|     0.0|(1,[0],[1.0])|\n",
      "|     1|        1|           4177|               1590|     0.0|(1,[0],[1.0])|\n",
      "+------+---------+---------------+-------------------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc9883f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f8ed028",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column Head Size(cm^3) must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.IntegerType$:int.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21632/2810938848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Head Size(cm^3)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Brain Weight(grams)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpipelineModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipelineModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# must be an Estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Column Head Size(cm^3) must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.IntegerType$:int."
     ]
    }
   ],
   "source": [
    "linear = LinearRegression(featuresCol='Head Size(cm^3)', labelCol='Brain Weight(grams)')\n",
    "pipeline = Pipeline(stages=[linear])\n",
    "pipelineModel = pipeline.fit(new_df)\n",
    "train_model = pipelineModel.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5016a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
